{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "from pandas import read_csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Flatten\n",
    "from keras.layers import Dropout\n",
    "from keras.layers.convolutional import Conv1D\n",
    "from keras.layers.convolutional import MaxPooling1D\n",
    "from keras.utils import to_categorical\n",
    "from keras.layers.normalization import BatchNormalization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading The Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class WSJ():\n",
    "\n",
    "    def __init__(self):\n",
    "        self.dev_set = None\n",
    "        self.train_set = None\n",
    "        self.test_set = None\n",
    "    \n",
    "    @property\n",
    "    def dev(self):\n",
    "        if self.dev_set is None:\n",
    "            self.dev_set = load_raw('../input/masterclass-hw-1/', 'dev')\n",
    "        return self.dev_set\n",
    "\n",
    "    @property\n",
    "    def train(self):\n",
    "        if self.train_set is None:\n",
    "            self.train_set = load_raw('../input/masterclass-hw-1/', 'train')\n",
    "        return self.train_set\n",
    "  \n",
    "    @property\n",
    "    def test(self):\n",
    "        if self.test_set is None:\n",
    "            self.test_set = (np.load(os.path.join('../input/masterclass-hw-1/', 'test_data.npy'), encoding='bytes'), None)\n",
    "        return self.test_set\n",
    "    \n",
    "def load_raw(path, name):\n",
    "    print(os.path.join(path, '{}_data.npy'.format(name)))\n",
    "    return (\n",
    "        np.load(os.path.join(path, '{}_data.npy'.format(name)), encoding='bytes'), \n",
    "        np.load(os.path.join(path, '{}_labels.npy'.format(name)), encoding='bytes')\n",
    "        \n",
    "        #np.load('dev_data.npy', encoding='bytes',allow_pickle=True), \n",
    "        #np.load('dev_labels.npy', encoding='bytes',allow_pickle=True)\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = np.load(\"C:/bio/8th Sem/IDC 410 ML/Frame level Speech Recog/DATA/FINAL_train_data.npy\", allow_pickle=True,encoding=\"latin1\")\n",
    "train_labels = np.load(\"C:/bio/8th Sem/IDC 410 ML/Frame level Speech Recog/DATA/train_labels.npy\", allow_pickle=True,encoding=\"latin1\")\n",
    "\n",
    "\n",
    "dev_data = np.load(\"C:/bio/8th Sem/IDC 410 ML/Frame level Speech Recog/DATA/FINAL_dev_data.npy\", allow_pickle=True,encoding=\"latin1\")\n",
    "dev_labels = np.load(\"C:/bio/8th Sem/IDC 410 ML/Frame level Speech Recog/DATA/dev_labels.npy\", allow_pickle=True,encoding=\"latin1\")\n",
    "\n",
    "print(\"The shape of training data is\", train_data.shape, \"\\n The shape of the train labels is\", train_labels.shape, \"\\n The shape of the dev data is\", dev_data.shape, \"\\n The shape of the Dev Labels is\", dev_labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((9748009, 120), (9748009,), (1080827, 120), (1103,))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.shape, train_labels.shape, dev_data.shape, dev_labels.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The distribution of the Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training a model of 96 lakhs entries, consumed a lot of time, So, I trained a model on a subset of 12 lakh datasets. As their distribution is almost the same our training should not be baised"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Distribution of Original Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x504 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "  \n",
    "a = np.array(train_labels)\n",
    "\n",
    "# Creating histogram\n",
    "fig, ax = plt.subplots(figsize =(10, 7))\n",
    "ax.hist(a, bins = [0, 5, 10, 15,20,25,30,35,40,45,50,55,60,65,70,75,80,85,90,95,100,105,110,115,120,125,130,135,140])\n",
    "  \n",
    "# Show plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Distribution of Subset Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x504 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "  \n",
    "k = np.array(train_labels[1:1200000])\n",
    "\n",
    "# Creating histogram\n",
    "fig, ax = plt.subplots(figsize =(10, 7))\n",
    "ax.hist(k, bins = [0, 5, 10, 15,20,25,30,35,40,45,50,55,60,65,70,75,80,85,90,95,100,105,110,115,120,125,130,135,140])\n",
    "  \n",
    "# Show plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Shaping the Dataset for 1D CNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Since we are going to run the dataset on 1D CNN, we modified the data set initially using 3 contexts and then reshaping the dataset to fit in to the CNN and apply one hot encoding to the label data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((9748009, 120, 1), (9748009, 138))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "CNN_trainX = train_data.reshape(9748009, 120, 1)\n",
    "CNN_trainY = to_categorical(train_labels, num_classes=138)\n",
    "\n",
    "#CNN_testX = dev_data.reshape(1080827, 120, 1)\n",
    "#CNN_testY = to_categorical(dev_labels, num_classes=138)\n",
    "\n",
    "CNN_trainX.shape, CNN_trainY.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_7\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_23 (Conv1D)           (None, 119, 16)           48        \n",
      "_________________________________________________________________\n",
      "batch_normalization_23 (Batc (None, 119, 16)           64        \n",
      "_________________________________________________________________\n",
      "conv1d_24 (Conv1D)           (None, 117, 64)           3136      \n",
      "_________________________________________________________________\n",
      "batch_normalization_24 (Batc (None, 117, 64)           256       \n",
      "_________________________________________________________________\n",
      "max_pooling1d_22 (MaxPooling (None, 58, 64)            0         \n",
      "_________________________________________________________________\n",
      "conv1d_25 (Conv1D)           (None, 57, 32)            4128      \n",
      "_________________________________________________________________\n",
      "batch_normalization_25 (Batc (None, 57, 32)            128       \n",
      "_________________________________________________________________\n",
      "max_pooling1d_23 (MaxPooling (None, 28, 32)            0         \n",
      "_________________________________________________________________\n",
      "conv1d_26 (Conv1D)           (None, 26, 64)            6208      \n",
      "_________________________________________________________________\n",
      "batch_normalization_26 (Batc (None, 26, 64)            256       \n",
      "_________________________________________________________________\n",
      "max_pooling1d_24 (MaxPooling (None, 13, 64)            0         \n",
      "_________________________________________________________________\n",
      "conv1d_27 (Conv1D)           (None, 11, 128)           24704     \n",
      "_________________________________________________________________\n",
      "batch_normalization_27 (Batc (None, 11, 128)           512       \n",
      "_________________________________________________________________\n",
      "max_pooling1d_25 (MaxPooling (None, 5, 128)            0         \n",
      "_________________________________________________________________\n",
      "flatten_6 (Flatten)          (None, 640)               0         \n",
      "_________________________________________________________________\n",
      "dense_16 (Dense)             (None, 512)               328192    \n",
      "_________________________________________________________________\n",
      "dropout_9 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_17 (Dense)             (None, 512)               262656    \n",
      "_________________________________________________________________\n",
      "dropout_10 (Dropout)         (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_18 (Dense)             (None, 138)               70794     \n",
      "=================================================================\n",
      "Total params: 701,082\n",
      "Trainable params: 700,474\n",
      "Non-trainable params: 608\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "n_timesteps, n_features, n_outputs = CNN_trainX.shape[1], CNN_trainX.shape[2], CNN_trainY.shape[1]\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Conv1D(filters= 16, kernel_size= 2, activation='relu', input_shape=(n_timesteps,n_features)))\n",
    "model.add(BatchNormalization())\n",
    "\n",
    "model.add(Conv1D(filters= 64, kernel_size= 3, activation='relu', input_shape=(n_timesteps,n_features)))\n",
    "model.add(BatchNormalization())\n",
    "\n",
    "\n",
    "model.add(MaxPooling1D(pool_size=2))\n",
    "\n",
    "model.add(Conv1D(filters= 32, kernel_size= 2, activation='relu',  kernel_regularizer= tf.keras.regularizers.l2(l=0.01)))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPooling1D(pool_size=2))\n",
    "\n",
    "model.add(Conv1D(filters= 64, kernel_size= 3, activation='relu',  kernel_regularizer= tf.keras.regularizers.l2(l=0.01)))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPooling1D(pool_size=2))\n",
    "\n",
    "model.add(Conv1D(filters= 128, kernel_size= 3, activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "\n",
    "model.add(MaxPooling1D(pool_size=2))\n",
    "\n",
    "model.add(Flatten())\n",
    "\n",
    "model.add(Dense(512, activation='relu'))\n",
    "model.add(Dropout(0.3))\n",
    "model.add(Dense(512, activation='relu'))\n",
    "model.add(Dropout(0.3))\n",
    "model.add(Dense(n_outputs, activation='softmax'))\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\t# fit network\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training The Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "119999/119999 [==============================] - 90s 749us/step - loss: 2.4854 - accuracy: 0.3597\n",
      "Epoch 2/15\n",
      "119999/119999 [==============================] - 90s 753us/step - loss: 2.4244 - accuracy: 0.3722\n",
      "Epoch 3/15\n",
      "119999/119999 [==============================] - 91s 761us/step - loss: 2.3720 - accuracy: 0.3813\n",
      "Epoch 4/15\n",
      "119999/119999 [==============================] - 92s 768us/step - loss: 2.3320 - accuracy: 0.3898\n",
      "Epoch 5/15\n",
      "119999/119999 [==============================] - 90s 748us/step - loss: 2.2923 - accuracy: 0.3978\n",
      "Epoch 6/15\n",
      "119999/119999 [==============================] - 89s 742us/step - loss: 2.2583 - accuracy: 0.4046\n",
      "Epoch 7/15\n",
      "119999/119999 [==============================] - 90s 749us/step - loss: 2.2227 - accuracy: 0.4113\n",
      "Epoch 8/15\n",
      "119999/119999 [==============================] - 91s 755us/step - loss: 2.1991 - accuracy: 0.4162\n",
      "Epoch 9/15\n",
      "119999/119999 [==============================] - 90s 752us/step - loss: 2.1661 - accuracy: 0.4225\n",
      "Epoch 10/15\n",
      "119999/119999 [==============================] - 90s 753us/step - loss: 2.1374 - accuracy: 0.4282\n",
      "Epoch 11/15\n",
      "119999/119999 [==============================] - 91s 757us/step - loss: 2.1157 - accuracy: 0.4317\n",
      "Epoch 12/15\n",
      "119999/119999 [==============================] - 92s 768us/step - loss: 2.0871 - accuracy: 0.4373\n",
      "Epoch 13/15\n",
      "119999/119999 [==============================] - 92s 763us/step - loss: 2.0670 - accuracy: 0.4431\n",
      "Epoch 14/15\n",
      "119999/119999 [==============================] - 91s 762us/step - loss: 2.0463 - accuracy: 0.4477\n",
      "Epoch 15/15\n",
      "119999/119999 [==============================] - 91s 758us/step - loss: 2.0238 - accuracy: 0.4507\n"
     ]
    }
   ],
   "source": [
    "fit = model.fit(CNN_trainX[1:120000], CNN_trainY[1:120000], batch_size = 32,  verbose=True , epochs= 15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_, accuracy = model.evaluate(CNN_trainX[1200000:1500000], CNN_trainY[1200000:1500000], batch_size= 32, verbose= True)\n",
    "print(accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prediction\n",
    "\n",
    "### We load the test dataset on the kaggle and predict on the data using our trained 1D CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4620355, 120)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = np.load(\"C:/bio/8th Sem/IDC 410 ML/Frame level Speech Recog/DATA/test_data_v120.npy\", allow_pickle=True,encoding=\"latin1\")\n",
    "\n",
    "test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4620355,)"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "CNN_test = test.reshape(4620355, 120, 1)\n",
    "y_pred = model.predict_classes(CNN_test)\n",
    "y_pred.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Writing on the csv file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('C:/bio/8th Sem/IDC 410 ML/Frame level Speech Recog/DATA/Final_Submission6.csv', 'w') as w:\n",
    "    w.write('id,label\\n')\n",
    "    for i in range(len(y_pred)):\n",
    "            w.write(str(i)+','+str(y_pred[i])+'\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4620355, 2)"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "mycsv = pd.read_csv('C:/bio/8th Sem/IDC 410 ML/Frame level Speech Recog/DATA/Final_Submission6.csv')\n",
    "df = pd.DataFrame(mycsv)\n",
    "\n",
    "df.shape"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
